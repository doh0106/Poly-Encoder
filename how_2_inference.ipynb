{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/Poly-Encoder/\n",
    "\n",
    "from model_for_inference import Load_Model_Tokenizer\n",
    "from dasan_call import Call_Center\n",
    "import os\n",
    "import pickle\n",
    "import torch \n",
    "\n",
    "emb_dir = '/content/Poly-Encoder/datasets'  # candidates embedding df 저장된 directory\n",
    "model_dir = '/content/Poly-Encoder/bert_model' # 학습된 모델 directory\n",
    "\n",
    "with open(os.path.join(emb_dir, 'cand_embs.pickle'), 'rb') as f:\n",
    "    cand_embs_df = pickle.load(f)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model, tokenizer = Load_Model_Tokenizer(model_dir) \n",
    "model.to(device)\n",
    "\n",
    "call_center = Call_Center(model=model, tokenizer=tokenizer, cand_embs_df=cand_embs_df, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '집에 가고 싶다'\n",
    "answer = call_center.inference(query)\n",
    "print(f'질문 : {query}', f'대답 : {answer}', sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
