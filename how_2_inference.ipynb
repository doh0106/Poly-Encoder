{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd bert_model\n",
    "!gdown 1VtB3fYNVb7I1dIIB4PuYVJpvQatePsLz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .. # Poly-Enocder folder로 가도록\n",
    "\n",
    "CATEGORY = '' # normal, water, corona\n",
    "\n",
    "from model_for_inference import Load_Model_Tokenizer\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "emb_dir = 'datasets'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "with open(os.path.join(emb_dir, f'{CATEGORY}_emb.pickle'), 'rb') as f:      # q1, q2, q3, q4, response 임베딩값들 저장 pickle\n",
    "    embedding_df = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(emb_dir, f'd{CATEGORY}_text.pickle'), 'rb') as f:    # q1, q2, q3, q4, response 문장들 저장 pickle\n",
    "    text_df = pickle.load(f)            # -> 실제론 db에 저장되어있는 table사용 / 그냥 결과 그럴듯한지 보기 위해 불러옴\n",
    "\n",
    "model, tokenizer = Load_Model_Tokenizer('bert_model')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from 카테고리별inference import Category_Callcenter\n",
    "\n",
    "call_center = Category_Callcenter(model=model, tokenizer=tokenizer, emb_df=embedding_df, device=device)\n",
    "\n",
    "query = '집에 가고 싶다'\n",
    "answer_idx = call_center.inference(query)\n",
    "\n",
    "print('질문 : ', query)\n",
    "print('대답 : ', text_df.iloc[call_center.inference(query)]['response'])\n",
    "print('='*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
